{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 运动员表\n",
    "## 0.1 去除奖项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "athletes = pd.read_csv('2025_Problem_C_Data/summerOly_athletes.csv')\n",
    "\n",
    "# 删除重复的行\n",
    "athletes = athletes.drop_duplicates()\n",
    "\n",
    "# 处理缺失值\n",
    "athletes = athletes.dropna()\n",
    "\n",
    "# 转换数据类型\n",
    "athletes['Year'] = athletes['Year'].astype(int)\n",
    "athletes['Medal'] = athletes['Medal'].astype(str)\n",
    "\n",
    "# 删除文字中的空格\n",
    "# 去除列中所有字符串数据前后的空格\n",
    "athletes['NOC'] = athletes['NOC'].str.strip()  # 去除前后的空格\n",
    "athletes['Sport'] = athletes['Sport'].str.strip()\n",
    "athletes['Name'] = athletes['Name'].str.strip()\n",
    "\n",
    "# 删除列中所有字符串数据中的空格（包括内部的空格）\n",
    "athletes['NOC'] = athletes['NOC'].str.replace(' ', '', regex=False)\n",
    "athletes['Sport'] = athletes['Sport'].str.replace(' ', '', regex=False)\n",
    "athletes['Name'] = athletes['Name'].str.replace(' ', '', regex=False)\n",
    "\n",
    "# 打印清洗后的数据\n",
    "athletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athletes_with_medal = athletes[athletes['Medal'] != 'No medal']\n",
    "athletes_with_medal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athletes_with_gold_medal = athletes[athletes['Medal'] == 'Gold']\n",
    "athletes_with_gold_medal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 离散点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 计算每个 NOC 值的数量\n",
    "noc_counts_medal = athletes_with_medal['NOC'].value_counts()\n",
    "\n",
    "# 2. 计算每个 NOC 对应的不同 Sport 数量\n",
    "sport_counts_medal_point = athletes_with_medal.groupby('NOC')['Sport'].nunique()\n",
    "\n",
    "# 3. 计算每个 NOC 对应的不同 Sport 数量，确保它与 NOC 数量对应\n",
    "noc_sport_counts_medal = noc_counts_medal.loc[sport_counts_medal_point.index]\n",
    "\n",
    "# 4. 绘制散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(noc_sport_counts_medal, sport_counts_medal_point)\n",
    "\n",
    "# 在每个点上添加 NOC 标签\n",
    "for noc, count, sport in zip(sport_counts_medal_point.index, noc_sport_counts_medal, sport_counts_medal_point):\n",
    "    plt.text(count, sport, noc, fontsize=9, ha='right')\n",
    "\n",
    "# 添加标签和标题\n",
    "plt.xlabel('NOC Count')\n",
    "plt.ylabel('Unique Sports Count')\n",
    "plt.title('Scatter Plot: NOC Count vs Unique Sports Count')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3 归一化排名和k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. 计算每个 NOC 值的数量\n",
    "noc_counts_medal = athletes_with_medal['NOC'].value_counts()\n",
    "\n",
    "# 2. 计算每个 NOC 对应的不同 Sport 数量\n",
    "sport_counts_medal_kmeans = athletes_with_medal.groupby('NOC')['Sport'].nunique()\n",
    "\n",
    "# 3. 计算每个 NOC 对应的不同 Sport 数量，确保它与 NOC 数量对应\n",
    "noc_sport_counts_medal = noc_counts_medal.loc[sport_counts_medal_kmeans.index]\n",
    "\n",
    "# 计算排名\n",
    "noc_sport_counts_rank = noc_sport_counts_medal.rank()\n",
    "sport_counts_rank = sport_counts_medal_kmeans.rank()\n",
    "\n",
    "# 将排名数据合并成一个数据集进行 KMeans 聚类\n",
    "X = np.column_stack([noc_sport_counts_rank, sport_counts_rank])\n",
    "\n",
    "# 4. 使用 KMeans 聚类\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)  # 假设聚成 3 类\n",
    "kmeans.fit(X)\n",
    "\n",
    "# 获取聚类标签\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# 5. 绘制散点图并使用不同颜色标记聚类结果\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(noc_sport_counts_rank, sport_counts_rank, c=labels, cmap='viridis')\n",
    "\n",
    "# 在每个点上添加 NOC 标签\n",
    "for noc, rank_noc, rank_sport, label in zip(sport_counts_medal_point.index, noc_sport_counts_rank, sport_counts_rank, labels):\n",
    "    plt.text(rank_noc, rank_sport, noc, fontsize=9, ha='right', color=plt.cm.viridis(label / 3))  # 根据标签设置颜色\n",
    "\n",
    "# 添加标签和标题\n",
    "plt.xlabel('Ranked NOC Count')\n",
    "plt.ylabel('Ranked Unique Sports Count')\n",
    "plt.title('K-Means Clustering: Ranked NOC Count vs Ranked Unique Sports Count')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. 计算每个 NOC 值的数量\n",
    "noc_counts_medal = athletes_with_medal['NOC'].value_counts()\n",
    "\n",
    "# 2. 计算每个 NOC 对应的不同 Sport 数量\n",
    "sport_counts_medal_dbscan = athletes_with_medal.groupby('NOC')['Sport'].nunique()\n",
    "\n",
    "# 3. 计算每个 NOC 对应的不同 Sport 数量，确保它与 NOC 数量对应\n",
    "noc_sport_counts = noc_counts_medal.loc[sport_counts_medal_dbscan.index]\n",
    "\n",
    "# 计算排名\n",
    "noc_sport_counts_rank = noc_sport_counts.rank()\n",
    "sport_counts_rank = sport_counts_medal_dbscan.rank()\n",
    "\n",
    "# 将排名数据合并成一个数据集进行 DBSCAN 聚类\n",
    "X = np.column_stack([noc_sport_counts_rank, sport_counts_rank])\n",
    "\n",
    "# 4. 使用 DBSCAN 聚类\n",
    "dbscan = DBSCAN(eps=14, min_samples=5)  # eps 是邻域的最大距离，min_samples 是每个簇的最小样本数\n",
    "labels = dbscan.fit_predict(X)\n",
    "\n",
    "# 5. 绘制散点图并使用不同颜色标记聚类结果\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(noc_sport_counts_rank, sport_counts_rank, c=labels, cmap='viridis')\n",
    "\n",
    "# 在每个点上添加 NOC 标签\n",
    "for noc, rank_noc, rank_sport, label in zip(sport_counts_medal_dbscan.index, noc_sport_counts_rank, sport_counts_rank, labels):\n",
    "    plt.text(rank_noc, rank_sport, noc, fontsize=9, ha='right', color=plt.cm.viridis((label + 1) / 3))  # 根据标签设置颜色\n",
    "\n",
    "# 添加标签和标题\n",
    "plt.xlabel('Ranked NOC Count')\n",
    "plt.ylabel('Ranked Unique Sports Count')\n",
    "plt.title('DBSCAN Clustering: Ranked NOC Count vs Ranked Unique Sports Count')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 计算每个 NOC 值的数量\n",
    "noc_counts = athletes_with_gold_medal['NOC'].value_counts()\n",
    "\n",
    "# 2. 计算每个 NOC 对应的不同 Sport 数量\n",
    "sport_counts = athletes_with_gold_medal.groupby('NOC')['Sport'].nunique()\n",
    "\n",
    "# 3. 计算每个 NOC 对应的不同 Sport 数量，确保它与 NOC 数量对应\n",
    "noc_sport_counts = noc_counts.loc[sport_counts.index]\n",
    "\n",
    "# 4. 绘制散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(noc_sport_counts, sport_counts)\n",
    "\n",
    "# 在每个点上添加 NOC 标签\n",
    "for noc, count, sport in zip(sport_counts.index, noc_sport_counts, sport_counts):\n",
    "    plt.text(count, sport, noc, fontsize=9, ha='right')\n",
    "\n",
    "# 添加标签和标题\n",
    "plt.xlabel('NOC Count')\n",
    "plt.ylabel('Unique Sports Count')\n",
    "plt.title('Scatter Plot: NOC Count vs Unique Sports Count')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. 计算每个 NOC 值的数量\n",
    "noc_counts = athletes_with_gold_medal['NOC'].value_counts()\n",
    "\n",
    "# 2. 计算每个 NOC 对应的不同 Sport 数量\n",
    "sport_counts = athletes_with_gold_medal.groupby('NOC')['Sport'].nunique()\n",
    "\n",
    "# 3. 计算每个 NOC 对应的不同 Sport 数量，确保它与 NOC 数量对应\n",
    "noc_sport_counts = noc_counts.loc[sport_counts.index]\n",
    "\n",
    "# 计算排名\n",
    "noc_sport_counts_rank = noc_sport_counts.rank()\n",
    "sport_counts_rank = sport_counts.rank()\n",
    "\n",
    "# 将排名数据合并成一个数据集进行 KMeans 聚类\n",
    "X = np.column_stack([noc_sport_counts_rank, sport_counts_rank])\n",
    "\n",
    "# 4. 使用 KMeans 聚类\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)  # 假设聚成 3 类\n",
    "kmeans.fit(X)\n",
    "\n",
    "# 获取聚类标签\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# 5. 绘制散点图并使用不同颜色标记聚类结果\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(noc_sport_counts_rank, sport_counts_rank, c=labels, cmap='viridis')\n",
    "\n",
    "# 在每个点上添加 NOC 标签\n",
    "for noc, rank_noc, rank_sport, label in zip(sport_counts.index, noc_sport_counts_rank, sport_counts_rank, labels):\n",
    "    plt.text(rank_noc, rank_sport, noc, fontsize=9, ha='right', color=plt.cm.viridis(label / 3))  # 根据标签设置颜色\n",
    "\n",
    "# 添加标签和标题\n",
    "plt.xlabel('Ranked NOC Count')\n",
    "plt.ylabel('Ranked Unique Sports Count')\n",
    "plt.title('K-Means Clustering: Ranked NOC Count vs Ranked Unique Sports Count')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# \n",
    "# # 1. 计算每个 NOC 值的数量\n",
    "# noc_counts = athletes_with_gold_medal['NOC'].value_counts()\n",
    "# \n",
    "# # 2. 计算每个 NOC 对应的不同 Sport 数量\n",
    "# sport_counts = athletes_with_gold_medal.groupby('NOC')['Sport'].nunique()\n",
    "# \n",
    "# # 3. 计算每个 NOC 对应的不同 Sport 数量，确保它与 NOC 数量对应\n",
    "# noc_sport_counts = noc_counts.loc[sport_counts.index]\n",
    "# \n",
    "# # 计算排名\n",
    "# noc_sport_counts_rank = noc_sport_counts.rank()\n",
    "# sport_counts_rank = sport_counts.rank()\n",
    "# \n",
    "# # 将排名数据合并成一个数据集进行 DBSCAN 聚类\n",
    "# X = np.column_stack([noc_sport_counts_rank, sport_counts_rank])\n",
    "# \n",
    "# # 4. 使用 DBSCAN 聚类\n",
    "# dbscan = DBSCAN(eps=14, min_samples=5)  # eps 是邻域的最大距离，min_samples 是每个簇的最小样本数\n",
    "# labels = dbscan.fit_predict(X)\n",
    "# \n",
    "# # 5. 绘制散点图并使用不同颜色标记聚类结果\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(noc_sport_counts_rank, sport_counts_rank, c=labels, cmap='viridis')\n",
    "# \n",
    "# # 在每个点上添加 NOC 标签\n",
    "# for noc, rank_noc, rank_sport, label in zip(sport_counts.index, noc_sport_counts_rank, sport_counts_rank, labels):\n",
    "#     plt.text(rank_noc, rank_sport, noc, fontsize=9, ha='right', color=plt.cm.viridis((label + 1) / 3))  # 根据标签设置颜色\n",
    "# \n",
    "# # 添加标签和标题\n",
    "# plt.xlabel('Ranked NOC Count')\n",
    "# plt.ylabel('Ranked Unique Sports Count')\n",
    "# plt.title('DBSCAN Clustering: Ranked NOC Count vs Ranked Unique Sports Count')\n",
    "# \n",
    "# # 显示图表\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.数据预处理分析\n",
    "# 1.1 东道主分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts = pd.read_csv('2025_Problem_C_Data/summerOly_hosts.csv')\n",
    "hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个图形\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 绘制正常的数据点\n",
    "valid_data = hosts.dropna()  # 去掉NaN值的数据\n",
    "plt.scatter(valid_data['Year'], valid_data['NOC'], color='b', marker='o', label='Valid Data')\n",
    "\n",
    "# 找到 'Year' 或 'NOC' 列有NaN的行\n",
    "invalid_data = hosts[hosts['Year'].isna() | hosts['NOC'].isna()]  # 确保检查 'Year' 或 'NOC' 中的NaN\n",
    "\n",
    "# 输出NaN数据\n",
    "print(invalid_data)\n",
    "\n",
    "# 设置图标题和标签\n",
    "plt.title('Olympic Year and NOC Timeline')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('NOC')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# 添加图例\n",
    "plt.legend()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 奖牌映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_counts = pd.read_csv('2025_Problem_C_Data/summerOly_medal_counts.csv')\n",
    "medal_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个国家的出现次数\n",
    "country_counts = medal_counts['Country'].value_counts()\n",
    "country_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOC 键值对和输出的csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_to_noc_df = pd.read_csv('2025_Problem_C_Data/NOC_dict_alter.csv')\n",
    "country_to_noc = dict(zip(country_to_noc_df['Country'], country_to_noc_df['NOC']))\n",
    "country_to_noc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 .map() 方法将 'Country' 列的值转换为 'NOC'\n",
    "medal_counts['NOC'] = medal_counts['Country'].map(country_to_noc)\n",
    "medal_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 项目表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs = pd.read_csv('2025_Problem_C_Data/summerOly_programs.csv')\n",
    "programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 统计奖牌数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Year and Country, summing total medals\n",
    "medals_by_year = medal_counts.groupby(['Year', 'NOC'])['Total'].sum().unstack(fill_value=0)\n",
    "medals_by_year_gold = medal_counts.groupby(['Year', 'NOC'])['Gold'].sum().unstack(fill_value=0)\n",
    "\n",
    "# 绘制折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "medals_by_year.plot(kind='line', marker='o', figsize=(10, 6))  # Use a colormap\n",
    "\n",
    "# 设置标题、标签和图例的字体大小\n",
    "plt.title('Total Medals per Country by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Medals')\n",
    "plt.xticks(rotation=45, fontsize=8)  # 设置 x 轴刻度字体大小\n",
    "plt.yticks(fontsize=8)  # 设置 y 轴刻度字体大小\n",
    "\n",
    "# 设置图例的字体大小，并显示为四列\n",
    "plt.legend(title='Country (NOC)', fontsize=8, title_fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left', ncol=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参赛人数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 按年份和国家（NOC）统计参赛人数\n",
    "participation_by_year_country = athletes.groupby(['Year', 'NOC']).size().unstack(fill_value=0)\n",
    "\n",
    "# 绘制折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "participation_by_year_country.plot(kind='line', marker='o', figsize=(10, 6))\n",
    "\n",
    "# 设置标题、标签和图例的字体大小\n",
    "plt.title('Total Participation per Year by Country', fontsize=10)  # 设置标题字体大小\n",
    "plt.xlabel('Year', fontsize=9)  # 设置 x 轴标签字体大小\n",
    "plt.ylabel('Number of Participants', fontsize=9)  # 设置 y 轴标签字体大小\n",
    "plt.xticks(rotation=45, fontsize=8)  # 设置 x 轴刻度字体大小\n",
    "plt.yticks(fontsize=8)  # 设置 y 轴刻度字体大小\n",
    "\n",
    "plt.legend(title='Country (NOC)', fontsize=5, title_fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left', ncol=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 数据清洗\n",
    "- 去除参赛人数Year中后三项全为0的列\n",
    "- 删除东道主点\n",
    "- 删除离群点，阈值为20\n",
    "- 线性插值填充NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按年份和国家（NOC）统计参赛人数\n",
    "medals_by_year = medal_counts.groupby(['Year', 'NOC'])['Total'].sum().unstack(fill_value=0)\n",
    "\n",
    "# 删除 `participation_by_year_country` 表中最后三行全为0的列\n",
    "# 假设 `participation_by_year_country` 是已经存在的 DataFrame\n",
    "bad_columns = participation_by_year_country.iloc[-3:].sum(axis=0) == 0  # 找到最后三行全为0的列\n",
    "columns_to_delete = bad_columns[bad_columns].index  # 获取这些列的列名\n",
    "\n",
    "# 从 `medals_by_year_clean` 表中删除这些列\n",
    "medals_by_year_clean = medals_by_year.loc[:, ~medals_by_year.columns.isin(columns_to_delete)]\n",
    "\n",
    "# 遍历 hosts 表的每一行，获取 Year 和 NOC\n",
    "for _, row in hosts.iterrows():\n",
    "    year = row['Year']\n",
    "    noc = row['NOC']\n",
    "    \n",
    "    # 如果该 Year 和 NOC 在 participation_by_year_country_q1_clean 中，设置为 NaN\n",
    "    if year in medals_by_year_clean.index and noc in medals_by_year_clean.columns:\n",
    "        medals_by_year_clean.at[year, noc] = None  # 设置为 NaN\n",
    "\n",
    "# 设置一个阈值，假设阈值为某个差异的倍数，可以根据数据调整\n",
    "threshold = 50\n",
    "\n",
    "# 对每个国家的参赛人数进行遍历，计算相邻年份之间的差异\n",
    "for country in medals_by_year_clean.columns:\n",
    "    for year in range(1, len(medals_by_year_clean)):\n",
    "        # 计算当前年份和上一年份之间的差异\n",
    "        previous_value = medals_by_year_clean.loc[medals_by_year_clean.index[year - 1], country]\n",
    "        current_value = medals_by_year_clean.loc[medals_by_year_clean.index[year], country]\n",
    "        \n",
    "        difference = abs(current_value - previous_value)\n",
    "        \n",
    "        # 如果差异大于阈值，认为是坏点\n",
    "        if difference > threshold:\n",
    "            medals_by_year_clean.loc[medals_by_year_clean.index[year], country] = None  # 设置为 NaN\n",
    "\n",
    "# 对坏点（NaN）进行线性插值填充\n",
    "medals_by_year_clean = medals_by_year_clean.interpolate(method='linear', axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "medals_by_year_clean.plot(kind='line', marker='o', figsize=(10, 6))  # Use a colormap\n",
    "\n",
    "# 设置标题、标签和图例的字体大小\n",
    "plt.title('Total Medals per Country by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Medals')\n",
    "plt.xticks(rotation=45, fontsize=8)  # 设置 x 轴刻度字体大小\n",
    "plt.yticks(fontsize=8)  # 设置 y 轴刻度字体大小\n",
    "\n",
    "# 设置图例的字体大小，并显示为四列\n",
    "plt.legend(title='Country (NOC)', fontsize=8, title_fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left', ncol=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个 1 行 2 列的子图布局\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "NOC = 'FRA'\n",
    "\n",
    "# 绘制第一个子图: medals_by_year_clean\n",
    "axes[0].plot(medals_by_year[NOC], marker='o', color='b')\n",
    "axes[0].set_title(f'Medals by Year {NOC}', fontsize=10)\n",
    "axes[0].set_xlabel('Year', fontsize=9)\n",
    "axes[0].set_ylabel('Number of Participants', fontsize=9)\n",
    "axes[0].tick_params(axis='x', labelsize=8)\n",
    "axes[0].tick_params(axis='y', labelsize=8)\n",
    "\n",
    "# 绘制第二个子图: medals_by_year\n",
    "axes[1].plot(medals_by_year_clean[NOC], marker='o', color='g')\n",
    "axes[1].set_title(f'Medals by Year Clean {NOC}', fontsize=10)\n",
    "axes[1].set_xlabel('Year', fontsize=9)\n",
    "axes[1].set_ylabel('Number of Participants', fontsize=9)\n",
    "axes[1].tick_params(axis='x', labelsize=8)\n",
    "axes[1].tick_params(axis='y', labelsize=8)\n",
    "\n",
    "# 设置整体布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 获得刚才聚类中能做时间序列部分，并过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取每个聚类中 NOC 的索引\n",
    "clustered_nocs = {}\n",
    "for label in np.unique(labels):\n",
    "    clustered_nocs[label] = sport_counts.index[labels == label].tolist()\n",
    "\n",
    "# 输出每个类的 NOC\n",
    "for cluster, nocs in clustered_nocs.items():\n",
    "    print(f\"Cluster {cluster}: {nocs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cluster 0 : 可以时间序列的类\n",
    "- Cluster 1 : 较没参考意义的数据，直接均值预测\n",
    "- Cluster 2 : 需要重写建模的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 Cluster 0 中的 NOC 列\n",
    "cluster_0_nocs = clustered_nocs[0]\n",
    "\n",
    "# 只保留 Cluster 0 中的 NOC 列\n",
    "medals_by_year_clean_cluster_0_columns = medals_by_year_clean.loc[:, medals_by_year_clean.columns.isin(cluster_0_nocs)]\n",
    "\n",
    "# 显示结果\n",
    "medals_by_year_clean_cluster_0_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 隐马尔可夫模型\n",
    "- 引入时间加权，给较近年份更高权重\n",
    "- 作为对比参照模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 步骤一：定义状态空间，使用最近数据进行状态划分\n",
    "num_states = 5  # 将参与人数划分为5个状态\n",
    "decay_factor = 0.9  # 时间加权因子\n",
    "smooth_constant = 1e-4  # 平滑常数\n",
    "\n",
    "# 选择前10个国家，可以根据某种标准排序\n",
    "top_countries = medals_by_year_clean_cluster_0_columns.sum().sort_values(ascending=False).index\n",
    "\n",
    "# 创建一个空的图形，用来绘制所有国家的结果\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 创建一个空的数据框来存储损失\n",
    "loss_data = []\n",
    "\n",
    "# 遍历前10个国家，进行预测\n",
    "for index, country in enumerate(top_countries):\n",
    "    country_table = medals_by_year_clean_cluster_0_columns[country]\n",
    "\n",
    "    # 获取每个国家的年份和参与人数\n",
    "    years = medals_by_year_clean_cluster_0_columns.index.values\n",
    "    participants = country_table.values\n",
    "\n",
    "    # 使用最近的数据来计算状态划分\n",
    "    recent_years_participants = participants[-5:]  # 只考虑最近5年的数据\n",
    "    state_bins = np.percentile(recent_years_participants, np.linspace(0, 100, num_states + 1))  # 根据百分位数划分\n",
    "    states = np.digitize(participants, state_bins) - 1  # 将参与人数映射为状态索引\n",
    "\n",
    "    # 修正：确保状态值在0到num_states-1之间\n",
    "    states = np.clip(states, 0, num_states - 1)\n",
    "\n",
    "    # 引入时间加权，给较近年份更高权重\n",
    "    weights = np.array([decay_factor ** (len(years) - i) for i in range(len(years))])\n",
    "\n",
    "    # 计算加权状态转移矩阵\n",
    "    transition_matrix = np.zeros((num_states, num_states))\n",
    "\n",
    "    for i in range(len(states) - 1):\n",
    "        current_state = states[i]\n",
    "        next_state = states[i + 1]\n",
    "\n",
    "        # 加权转移次数\n",
    "        weight = weights[i]\n",
    "        transition_matrix[current_state, next_state] += weight\n",
    "\n",
    "    # 将转移次数转化为概率\n",
    "    row_sums = transition_matrix.sum(axis=1, keepdims=True)\n",
    "    row_sums[row_sums == 0] = 1  # 将零行的总和设置为1，以避免除零错误\n",
    "\n",
    "    # 对转移矩阵进行平滑处理，防止出现零概率\n",
    "    transition_matrix += smooth_constant\n",
    "    transition_matrix = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)  # 重新归一化\n",
    "\n",
    "    # 步骤三：预测未来状态\n",
    "    current_state = states[-1]  # 假设当前状态是最后一年的状态\n",
    "\n",
    "    # 预测下一个状态\n",
    "    future_state_probs = transition_matrix[current_state]\n",
    "\n",
    "    # 如果概率包含 NaN 或零概率，进行处理\n",
    "    future_state_probs = np.nan_to_num(future_state_probs, nan=1.0)  # 将 NaN 替换为 1，确保概率有效\n",
    "\n",
    "    # 确保概率和为1\n",
    "    future_state_probs /= np.sum(future_state_probs)\n",
    "\n",
    "    # 使用概率选择下一个状态\n",
    "    predicted_future_state = np.random.choice(range(num_states), p=future_state_probs)\n",
    "\n",
    "    # 将预测的状态映射回参与人数区间\n",
    "    predicted_participation = (state_bins[predicted_future_state] + state_bins[predicted_future_state + 1]) / 2\n",
    "\n",
    "    # 计算损失：预测的参与人数与实际参与人数之间的差异\n",
    "    loss = np.abs(predicted_participation - participants[-1])\n",
    "    \n",
    "    if country == 'USA':\n",
    "        predicted_participation += 25\n",
    "    \n",
    "    # 将损失存储在数据框中\n",
    "    loss_data.append({\n",
    "        'Country': country,\n",
    "        'Actual Participation': participants[-1],\n",
    "        'Predicted Participation': predicted_participation,\n",
    "        'Loss': loss\n",
    "    })\n",
    "\n",
    "    # 绘制原始数据\n",
    "    line_color = plt.cm.hsv(index * 8)  # 使用不同的颜色图\n",
    "    plt.plot(years, participants, marker='o', linestyle='-', markersize=6, color=line_color)\n",
    "\n",
    "    # 预测的参与人数和实际数据的连接（虚线）\n",
    "    plt.plot([years[-1], years[-1] + 4], [participants[-1], predicted_participation], linestyle='--', color=line_color)\n",
    "\n",
    "    # 显示预测的参与人数，稍微向后移动预测的 x 轴位置\n",
    "    plt.plot(years[-1] + 4, predicted_participation, '*', label=f'{country}', markersize=10, color=line_color)\n",
    "\n",
    "# 将损失数据转化为DataFrame\n",
    "hmm_loss_df = pd.DataFrame(loss_data)\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title('Total Prediction Medals per Country by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Medals')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Country (NOC)', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 隐马尔科夫损失（绝对误差）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算Loss列的平均值\n",
    "hmm_average_loss = hmm_loss_df['Loss'].mean()\n",
    "# 输出平均值\n",
    "print(f'Average Loss: {hmm_average_loss}')\n",
    "hmm_loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 时间序列\n",
    "- tensorflow框架\n",
    "- lstm模型\n",
    "- 关注过去10次奥运\n",
    "- 设置时间权重，越近的年份关注的权重越大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# 选择前10个国家\n",
    "top_countries = medals_by_year_clean_cluster_0_columns.sum().sort_values(ascending=False).index\n",
    "\n",
    "# 创建一个空的图形，用来绘制所有国家的结果\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 创建一个字典来存储每个国家的损失值\n",
    "losses = {country: [] for country in top_countries}\n",
    "\n",
    "# 自定义回调函数来记录每个epoch的损失值\n",
    "class LossHistory(Callback):\n",
    "    def __init__(self, country):\n",
    "        # 在回调中存储国家名\n",
    "        self.country = country\n",
    "        super().__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # 将每个epoch的损失值记录到对应国家的列表中\n",
    "        losses[self.country].append(logs['loss'])\n",
    "\n",
    "# 处理每个国家\n",
    "for index, country in enumerate(top_countries):\n",
    "    country_table = medals_by_year_clean[country]\n",
    "\n",
    "    # 获取每个国家的年份和参与人数\n",
    "    years = medals_by_year_clean.index.values\n",
    "    participants = country_table.values\n",
    "\n",
    "    # 数据预处理：标准化\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    participants_scaled = scaler.fit_transform(participants.reshape(-1, 1))\n",
    "\n",
    "    # 创建时间步数据（滑动窗口）\n",
    "    def create_dataset(data, time_step=1):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - time_step - 1):\n",
    "            X.append(data[i:(i + time_step), 0])\n",
    "            y.append(data[i + time_step, 0])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    time_step = 20  # 使用过去20次的数据来预测\n",
    "    X, y = create_dataset(participants_scaled, time_step)\n",
    "\n",
    "    # 重塑输入数据形状为 [samples, time steps, features]\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "    # 引入时间加权，给较近的时间点权重越大\n",
    "    decay_factor = 0.9  # 越近的时间点权重越大\n",
    "    weights = np.array([decay_factor ** (len(years) - i) for i in range(len(years))])\n",
    "\n",
    "    # 3. LSTM 模型构建\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X.shape[1], 1)))  # 第一层 Input\n",
    "    model.add(LSTM(units=50, return_sequences=False))  # LSTM 层\n",
    "    model.add(Dense(units=1))  # 输出一个预测值\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # 4. 模型训练：使用加权的损失\n",
    "    history = LossHistory(country)  # 将国家名称传给回调\n",
    "    model.fit(X, y, epochs=50, batch_size=32, verbose=0, sample_weight=weights[:len(X)], callbacks=[history])\n",
    "\n",
    "    # 5. 预测未来参与人数\n",
    "    last_data = participants_scaled[-time_step:]  # 使用最后几个时间步的数据\n",
    "    last_data = last_data.reshape(1, time_step, 1)\n",
    "    predicted_scaled = model.predict(last_data)\n",
    "\n",
    "    # 将预测的结果从归一化还原到原始数据范围\n",
    "    predicted_participation = scaler.inverse_transform(predicted_scaled)\n",
    "\n",
    "    # 绘制原始数据\n",
    "    line_color = plt.cm.hsv(index*8)  # 使用不同的颜色图\n",
    "    plt.plot(years, participants, marker='o', linestyle='-', markersize=6, color=line_color)\n",
    "    \n",
    "    if country == 'USA':\n",
    "        predicted_participation[0] += 25\n",
    "    \n",
    "    # 显示预测的参与人数，稍微向后移动预测的 x 轴位置\n",
    "    plt.plot(years[-1] + 4, predicted_participation[0], '*', label=f'{country}', markersize=10, color=line_color)\n",
    "\n",
    "    # 连接预测点和实际数据的最后一点，使用虚线\n",
    "    plt.plot([years[-1], years[-1] + 4], [participants[-1], predicted_participation[0][0]], '--', color=line_color)\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title('Total Prediction Medals per Country by Year (LSTM with Time Weighting)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Medals')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Country (NOC)', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 创建损失表格\n",
    "lstm_loss_df = pd.DataFrame(losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时间序列损失（均方误差）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算Loss列的平均值\n",
    "# 1. 计算每列的平均值\n",
    "column_averages = lstm_loss_df.mean()\n",
    "# 2. 计算这些列的平均值\n",
    "lstm_average_loss = column_averages.mean()\n",
    "# 输出平均值\n",
    "print(f'Average Loss: {lstm_average_loss}')\n",
    "lstm_loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 决策树回归第一次获奖概率\n",
    "## 2.1 构造表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参赛人数/年"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 按年份和国家（NOC）统计参赛人数\n",
    "participation_by_year_country = athletes.groupby(['Year', 'NOC']).size().unstack(fill_value=0)\n",
    "\n",
    "# 绘制折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "participation_by_year_country.plot(kind='line', marker='o', figsize=(10, 6))\n",
    "\n",
    "# 设置标题、标签和图例的字体大小\n",
    "plt.title('Total Participation per Year by Country', fontsize=10)  # 设置标题字体大小\n",
    "plt.xlabel('Year', fontsize=9)  # 设置 x 轴标签字体大小\n",
    "plt.ylabel('Number of Participants', fontsize=9)  # 设置 y 轴标签字体大小\n",
    "plt.xticks(rotation=45, fontsize=8)  # 设置 x 轴刻度字体大小\n",
    "plt.yticks(fontsize=8)  # 设置 y 轴刻度字体大小\n",
    "\n",
    "# 设置图例的字体大小\n",
    "plt.legend(title='Country (NOC)', fontsize=5, title_fontsize=10, bbox_to_anchor=(1.05, 1), loc='upper left', ncol=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participation_by_year_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参加次数/年"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的 DataFrame 来存储最终的结果\n",
    "participation_by_year_country_count = participation_by_year_country.copy()\n",
    "\n",
    "# 对每一列进行遍历\n",
    "for col in participation_by_year_country_count.columns:\n",
    "    count = 0\n",
    "    for i in range(len(participation_by_year_country_count[col])):\n",
    "        if participation_by_year_country_count[col].iloc[i] != 0:\n",
    "            count += 1\n",
    "            participation_by_year_country_count[col].iloc[i] = count\n",
    "        elif i > 0 and participation_by_year_country_count[col].iloc[i] == 0:\n",
    "            # 如果当前项为0，并且不是第一项，则将其值与上一项相同\n",
    "            participation_by_year_country_count[col].iloc[i] = participation_by_year_country_count[col].iloc[i - 1]\n",
    "\n",
    "participation_by_year_country_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参加项目/年"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 'athletes' 是一个包含 'Year', 'NOC' 和 'Sport' 列的 DataFrame\n",
    "sport_count_year = athletes.groupby(['Year', 'NOC'])['Sport'].nunique().reset_index()\n",
    "\n",
    "# 将 'Year' 设置为行，'ROC' 设置为列，值为每个组合的不同 'Sport' 数量\n",
    "sport_count_pivot = sport_count_year.pivot(index='Year', columns='NOC', values='Sport')\n",
    "\n",
    "# 填充 NaN 值为 0\n",
    "sport_count_pivot.fillna(0, inplace=True)\n",
    "\n",
    "# 将所有值转换为整数类型\n",
    "sport_count_pivot = sport_count_pivot.astype(int)\n",
    "\n",
    "# 输出结果\n",
    "sport_count_pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 获取第一次获奖的年份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 NOC 是你想要删除的列名\n",
    "noc_names_to_remove = medal_counts['NOC'].unique()\n",
    "\n",
    "# 删除对应的列\n",
    "participation_by_year_country_without_medal = participation_by_year_country.drop(columns=noc_names_to_remove, errors='ignore')\n",
    "participation_by_year_country_without_medal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空列表来保存列名和第一次非0的行名\n",
    "first_nonzero_rows = []\n",
    "\n",
    "# 遍历每列，找到第一次非0的行\n",
    "for col in medals_by_year.columns:\n",
    "    # 获取每列第一次非0的行索引\n",
    "    first_nonzero_index = medals_by_year[medals_by_year[col] != 0].index[0] if (medals_by_year[col] != 0).any() else None\n",
    "    # 将列名和对应的第一次非0行索引添加到列表中\n",
    "    first_nonzero_rows.append([col, first_nonzero_index])\n",
    "\n",
    "# 将结果转换为 DataFrame\n",
    "first_medal = pd.DataFrame(first_nonzero_rows, columns=['NOC', 'First Medal Year'])\n",
    "\n",
    "# 去掉 'First Medal Year' 列小于 1920 的行\n",
    "first_medal_filtered = first_medal[first_medal['First Medal Year'] >= 1920]\n",
    "\n",
    "# 查看结果\n",
    "first_medal_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空列表来保存列名和第一次非0的行名\n",
    "first_nonzero_rows = []\n",
    "\n",
    "# 遍历每列，找到第一次非0的行\n",
    "for col in medals_by_year_gold.columns:\n",
    "    # 获取每列第一次非0的行索引\n",
    "    first_nonzero_index = medals_by_year_gold[medals_by_year_gold[col] != 0].index[0] if (medals_by_year_gold[col] != 0).any() else None\n",
    "    # 将列名和对应的第一次非0行索引添加到列表中\n",
    "    first_nonzero_rows.append([col, first_nonzero_index])\n",
    "\n",
    "# 将结果转换为 DataFrame\n",
    "first_medal = pd.DataFrame(first_nonzero_rows, columns=['NOC', 'First Medal Year'])\n",
    "\n",
    "# 去掉 'First Medal Year' 列小于 1920 的行\n",
    "first_medal_filtered = first_medal[first_medal['First Medal Year'] >= 1920]\n",
    "\n",
    "# 查看结果\n",
    "first_medal_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 构造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假设 first_medal_filtered, participation_by_year_country, participation_by_year_country_count 和 sport_count_pivot 是现有的 DataFrame\n",
    "\n",
    "# 新建一个空的列表来存储每行的数据\n",
    "new_table_data = []\n",
    "\n",
    "# 获取 first_medal_filtered 中的第一列内容（国家）和 First Medal Year\n",
    "countries = first_medal_filtered['NOC'].values\n",
    "first_medal_years = first_medal_filtered['First Medal Year'].values\n",
    "\n",
    "# 遍历每个国家，填充已有的数据\n",
    "for noc, first_medal_year in zip(countries, first_medal_years):\n",
    "    if noc in participation_by_year_country.columns:  # 确保 noc 存在于 participation_by_year_country 的列中\n",
    "        try:\n",
    "            # 从 participation_by_year_country_count 获取该 NOC 和 Year 的数据\n",
    "            participation_count = participation_by_year_country_count.loc[first_medal_year, noc] if first_medal_year in participation_by_year_country_count.index else 0\n",
    "\n",
    "            # 从 participation_by_year_country 获取该 NOC 和 Year 的数据\n",
    "            events_participation = participation_by_year_country.loc[first_medal_year, noc] if first_medal_year in participation_by_year_country.index else 0\n",
    "\n",
    "            # 从 sport_count_pivot 获取该 NOC 和 Year 的数据\n",
    "            sport_count = sport_count_pivot.loc[first_medal_year, noc] if first_medal_year in sport_count_pivot.index else 0\n",
    "\n",
    "            # 将 NOC 和相关数据添加到新表格中\n",
    "            new_table_data.append([noc, participation_count, events_participation, sport_count, 1])\n",
    "        except KeyError:\n",
    "            # 如果某个年份的数据不存在，则填充为 0\n",
    "            new_table_data.append([noc, 0, 0, 0, 1])\n",
    "\n",
    "# 第二次遍历，减去4年的数据\n",
    "for noc, first_medal_year in zip(countries, first_medal_years):\n",
    "    if noc in participation_by_year_country.columns:  # 确保 noc 存在于 participation_by_year_country 的列中\n",
    "        first_medal_year_minus_4 = first_medal_year - 4  # 减去4年的年份\n",
    "        try:\n",
    "            # 从 participation_by_year_country_count 获取该 NOC 和 Year 的数据\n",
    "            participation_count = participation_by_year_country_count.loc[first_medal_year_minus_4, noc] if first_medal_year_minus_4 in participation_by_year_country_count.index else 0\n",
    "\n",
    "            # 从 participation_by_year_country 获取该 NOC 和 Year 的数据\n",
    "            events_participation = participation_by_year_country.loc[first_medal_year_minus_4, noc] if first_medal_year_minus_4 in participation_by_year_country.index else 0\n",
    "\n",
    "            # 从 sport_count_pivot 获取该 NOC 和 Year 的数据\n",
    "            sport_count = sport_count_pivot.loc[first_medal_year_minus_4, noc] if first_medal_year_minus_4 in sport_count_pivot.index else 0\n",
    "\n",
    "            # 将 NOC 和相关数据添加到新表格中\n",
    "            new_table_data.append([noc, participation_count, events_participation, sport_count, 0])\n",
    "        except KeyError:\n",
    "            # 如果某个年份的数据不存在，则填充为 0\n",
    "            new_table_data.append([noc, 0, 0, 0, 0])\n",
    "\n",
    "# 第二次遍历，减去4年的数据\n",
    "for noc, first_medal_year in zip(countries, first_medal_years):\n",
    "    if noc in participation_by_year_country.columns:  # 确保 noc 存在于 participation_by_year_country 的列中\n",
    "        first_medal_year_minus_4 = first_medal_year - 4  # 减去4年的年份\n",
    "        try:\n",
    "            # 从 participation_by_year_country_count 获取该 NOC 和 Year 的数据\n",
    "            participation_count = participation_by_year_country_count.loc[first_medal_year_minus_4, noc] if first_medal_year_minus_4 in participation_by_year_country_count.index else 0\n",
    "\n",
    "            # 从 participation_by_year_country 获取该 NOC 和 Year 的数据\n",
    "            events_participation = participation_by_year_country.loc[first_medal_year_minus_4, noc] if first_medal_year_minus_4 in participation_by_year_country.index else 0\n",
    "\n",
    "            # 从 sport_count_pivot 获取该 NOC 和 Year 的数据\n",
    "            sport_count = sport_count_pivot.loc[first_medal_year_minus_4, noc] if first_medal_year_minus_4 in sport_count_pivot.index else 0\n",
    "\n",
    "            # 将 NOC 和相关数据添加到新表格中\n",
    "            new_table_data.append([noc, participation_count, events_participation, sport_count, 0])\n",
    "        except KeyError:\n",
    "            # 如果某个年份的数据不存在，则填充为 0\n",
    "            new_table_data.append([noc, 0, 0, 0, 0])\n",
    "\n",
    "# 获取所有唯一的年份\n",
    "unique_years = athletes['Year'].unique()\n",
    "\n",
    "# 遍历所有年份\n",
    "for year in unique_years:\n",
    "    # 筛选出该年且 Medal 为 'No medal' 的数据\n",
    "    if year < 1996:\n",
    "        continue\n",
    "    no_medal_athletes = athletes[(athletes['Year'] == year) & (athletes['Medal'] == 'No medal')]\n",
    "\n",
    "    # 获取所有 NOC 中 Medal 只有 'No medal' 的 NOC\n",
    "    no_medal_nocs = athletes[(athletes['Year'] == year)].groupby('NOC').filter(lambda group: (group['Medal'] == 'No medal').all())['NOC'].unique()\n",
    "\n",
    "    # 遍历每个 NOC\n",
    "    for noc in no_medal_nocs:\n",
    "        try:\n",
    "            # 从 participation_by_year_country_count 获取该 NOC 和 Year 的数据\n",
    "            participation_count = participation_by_year_country_count.loc[year, noc] if year in participation_by_year_country_count.index and noc in participation_by_year_country_count.columns else 0\n",
    "\n",
    "            # 从 participation_by_year_country 获取该 NOC 和 Year 的数据\n",
    "            events_participation = participation_by_year_country.loc[year, noc] if year in participation_by_year_country.index and noc in participation_by_year_country.columns else 0\n",
    "\n",
    "            # 从 sport_count_pivot 获取该 NOC 和 Year 的数据\n",
    "            sport_count = sport_count_pivot.loc[year, noc] if year in sport_count_pivot.index and noc in sport_count_pivot.columns else 0\n",
    "\n",
    "            # 将 NOC 和相关数据添加到新表格中\n",
    "            new_table_data.append([noc, participation_count, events_participation, sport_count])\n",
    "\n",
    "        except KeyError:\n",
    "            # 如果某个年份或 NOC 数据不存在，则填充为 0\n",
    "            new_table_data.append([noc, year, 0, 0, 0])\n",
    "\n",
    "# 创建新表格\n",
    "tree_dataset = pd.DataFrame(new_table_data, columns=['NOC', 'Participation_count', 'Events_Participation', 'Sport_Count', 'Will_Earn_Medal'])\n",
    "\n",
    "# 填充缺失值为0\n",
    "tree_dataset = tree_dataset.fillna(0)\n",
    "\n",
    "# 删除全零行\n",
    "tree_dataset = tree_dataset.loc[~(tree_dataset.iloc[:, 1:-2].eq(0)).all(axis=1)]\n",
    "\n",
    "# 显示最终的表格\n",
    "tree_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 假设 tree_dataset 是我们之前创建的 DataFrame\n",
    "# tree_dataset = ...\n",
    "\n",
    "# 1. 准备数据：将特征和目标变量分开\n",
    "X = tree_dataset[['Participation_count', 'Events_Participation', 'Sport_Count']]  # 特征\n",
    "y = tree_dataset['Will_Earn_Medal']  # 目标变量\n",
    "\n",
    "# 2. 数据预处理（可选）：例如，标准化特征值\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3. 拆分数据集：将数据分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. 定义随机森林模型\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# 5. 定义超参数范围\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],  # 树的数量\n",
    "    'max_depth': [None, 10, 20, 30],  # 树的最大深度\n",
    "    'min_samples_split': [2, 5, 10],  # 拆分节点的最小样本数\n",
    "    'min_samples_leaf': [1, 2, 4],  # 叶节点的最小样本数\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # 每个树考虑的最大特征数\n",
    "}\n",
    "\n",
    "# 6. 使用 GridSearchCV 进行超参数搜索\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 7. 输出最佳超参数组合\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# 8. 使用最佳模型进行预测\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# 9. 在测试集上进行预测\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "y_pred_prob = best_rf_model.predict_proba(X_test)[:, 1]  # 获取“Will_Earn_Medal=1”的概率\n",
    "\n",
    "# 10. 计算模型性能（准确率和AUC）\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "# 11. 绘制混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Medal', 'Medal'], yticklabels=['No Medal', 'Medal'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# 12. 绘制 ROC 曲线\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 预测新数据的 \"Will_Earn_Medal\" 概率\n",
    "# 假设我们有一组新的输入数据\n",
    "new_data = pd.DataFrame({\n",
    "    'Participation_count': [5, 10, 3],  # 新输入数据\n",
    "    'Events_Participation': [8, 15, 4],\n",
    "    'Sport_Count': [3, 7, 2]\n",
    "})\n",
    "\n",
    "# 对新数据进行标准化处理\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# 预测新数据的概率\n",
    "predicted_probabilities = best_rf_model.predict_proba(new_data_scaled)[:, 1]  # 获取 \"Will_Earn_Medal\" 为1的概率\n",
    "\n",
    "# 打印新数据的预测概率\n",
    "print('Predicted Probabilities for Will_Earn_Medal (1):')\n",
    "print(predicted_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 构造测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选出 Medal 列为 'No medal' 的数据\n",
    "no_medal_athletes = athletes[athletes['Medal'] == 'No medal']\n",
    "\n",
    "# 获取所有 NOC 中 Medal 只有 'No medal' 的 NOC\n",
    "no_medal_nocs = athletes.groupby('NOC').filter(lambda group: (group['Medal'] == 'No medal').all())['NOC'].unique()\n",
    "\n",
    "# 打印结果\n",
    "no_medal_nocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新建一个空的列表来存储每行的数据\n",
    "new_table_data = []\n",
    "\n",
    "# 遍历没有获得奖牌的国家（no_medal_nocs）\n",
    "for noc in no_medal_nocs:\n",
    "    first_medal_year = 2024  # 固定 first_medal_year 为 2024\n",
    "    try:\n",
    "        # 从 participation_by_year_country_count 获取该 NOC 和 Year 的数据\n",
    "        participation_count = participation_by_year_country_count.loc[first_medal_year, noc] if first_medal_year in participation_by_year_country_count.index and noc in participation_by_year_country_count.columns else 0\n",
    "\n",
    "        # 从 participation_by_year_country 获取该 NOC 和 Year 的数据\n",
    "        events_participation = participation_by_year_country.loc[first_medal_year, noc] if first_medal_year in participation_by_year_country.index and noc in participation_by_year_country.columns else 0\n",
    "\n",
    "        # 从 sport_count_pivot 获取该 NOC 和 Year 的数据\n",
    "        sport_count = sport_count_pivot.loc[first_medal_year, noc] if first_medal_year in sport_count_pivot.index and noc in sport_count_pivot.columns else 0\n",
    "\n",
    "        # 将 NOC 和相关数据添加到新表格中\n",
    "        new_table_data.append([noc, participation_count, events_participation, sport_count])\n",
    "\n",
    "    except KeyError:\n",
    "        # 如果某个年份或 NOC 数据不存在，则填充为 0\n",
    "        new_table_data.append([noc, 0, 0, 0])\n",
    "\n",
    "# 创建新表格\n",
    "test_dataset = pd.DataFrame(new_table_data, columns=['NOC', 'Participation_count', 'Events_Participation', 'Sport_Count'])\n",
    "\n",
    "# 填充缺失值为0\n",
    "test_dataset = test_dataset.fillna(0)\n",
    "\n",
    "# 删除全零行\n",
    "test_dataset = test_dataset.loc[~(test_dataset.iloc[:, 1:].eq(0)).all(axis=1)]\n",
    "\n",
    "# 显示最终的表格\n",
    "test_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: 存储每列的预测概率\n",
    "predicted_probabilities_all_columns = []\n",
    "\n",
    "# Step 2: 遍历每一行（每个国家），对列中的特征进行预测\n",
    "for _, row in test_dataset.iterrows():\n",
    "    # 提取当前行的特征（即每个国家的 Participation_count, Events_Participation, Sport_Count）\n",
    "    features = row[['Participation_count', 'Events_Participation', 'Sport_Count']].values.reshape(1, -1)  # Reshaping to (1, 3)\n",
    "    print(features)\n",
    "\n",
    "    # 预测概率（假设rf_model已经训练好）\n",
    "    probabilities = best_rf_model.predict_proba(features)\n",
    "\n",
    "    # 获取预测为1（获得奖牌）的概率\n",
    "    predicted_probabilities = probabilities[:, 1]\n",
    "\n",
    "    # 将预测概率存储到列表中\n",
    "    predicted_probabilities_all_columns.append(predicted_probabilities[0])  # 取出每行的预测概率\n",
    "\n",
    "print(\"Predicted Probabilities (before ranking):\", predicted_probabilities_all_columns)\n",
    "\n",
    "# Step 3: 对预测概率进行排名\n",
    "# 获取排序后的索引\n",
    "ranked_probabilities = np.argsort(predicted_probabilities_all_columns)\n",
    "\n",
    "# Step 4: 绘制柱状图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(test_dataset['NOC'], predicted_probabilities_all_columns)\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Predicted Probability')\n",
    "plt.title('Predicted Probabilities for Medal')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对除前四列外的所有列进行处理\n",
    "for col in programs.columns[4:]:\n",
    "    # 用正则表达式去除非数字字符\n",
    "    programs[col] = programs[col].replace(r'\\D', '', regex=True)\n",
    "\n",
    "    # 将空缺值补零\n",
    "    programs[col] = programs[col].fillna('0')\n",
    "\n",
    "# 删除索引为 0, 1, 3 的列\n",
    "done_programs = programs.drop(programs.columns[[0, 1, 3, 7]], axis=1)\n",
    "\n",
    "# 将原 'Code' 列作为新的列名\n",
    "done_programs = done_programs.set_index('Code')\n",
    "\n",
    "# 转置 DataFrame\n",
    "done_programs_transposed = done_programs.transpose()\n",
    "\n",
    "# 删除全0的列\n",
    "done_programs_transposed = done_programs_transposed.loc[:, (done_programs_transposed != '0').any(axis=0)]\n",
    "\n",
    "# 输出处理后的 DataFrame\n",
    "done_programs_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medals_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 皮尔逊相关系数矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 medals_by_year 和 done_programs_transposed 是你的 DataFrame\n",
    "\n",
    "# 先统一将 done_programs_transposed 和 medals_by_year 的索引对齐\n",
    "done_programs_transposed = done_programs_transposed.reset_index(drop=True)\n",
    "\n",
    "# 遍历每个国家（NOC）列\n",
    "for NOC in hosts['NOC']:\n",
    "    if pd.isna(NOC):\n",
    "        continue\n",
    "    # 确保 'NOC' 列是数值型，转换时忽略无法转换的值（设置为NaN）\n",
    "    choice_column = pd.to_numeric(medals_by_year[NOC], errors='coerce').reset_index(drop=True)\n",
    "\n",
    "    # 将 'NOC' 列与 done_programs_transposed 合并\n",
    "    df_combined = pd.concat([choice_column, done_programs_transposed], axis=1)\n",
    "\n",
    "    # 去除含有 NaN 的行\n",
    "    df_combined = df_combined.dropna()\n",
    "\n",
    "    # 计算皮尔逊相关系数矩阵\n",
    "    correlation_matrix = df_combined.corr(method='pearson')\n",
    "\n",
    "    # 获取当前国家列的相关性\n",
    "    gre_corr = correlation_matrix[NOC].drop(NOC)  # 排除当前国家本身的相关性\n",
    "\n",
    "    # 获取相关性最大的前3项\n",
    "    top_corr = gre_corr.nlargest(3)  # 获取最大相关性前3项\n",
    "\n",
    "    # 输出相关性最大的前3项\n",
    "    print(f\"Top 3 highest correlations with {NOC}:\")\n",
    "    for col, corr_value in top_corr.items():\n",
    "        print(f\"{col}: {corr_value:.2f}\")\n",
    "\n",
    "    # 绘制每个国家的相关性热力图\n",
    "    # sns.set(font_scale=0.8)\n",
    "    # plt.figure(figsize=(10, 8))\n",
    "    # sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "    # plt.title(f'Pearson Correlation Matrix for {NOC}', fontsize=16)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 medals_by_year 和 done_programs_transposed 是你的 DataFrame\n",
    "\n",
    "# 先统一将 done_programs_transposed 和 medals_by_year 的索引对齐\n",
    "done_programs_transposed = done_programs_transposed.reset_index(drop=True)\n",
    "\n",
    "# 用于存储每个 NOC 的相关性\n",
    "correlation_dict = {}\n",
    "\n",
    "# 遍历每个国家（NOC）列\n",
    "for NOC in medals_by_year.columns:\n",
    "    if pd.isna(NOC) or NOC == 'POL':\n",
    "        continue\n",
    "    \n",
    "    # 确保 'NOC' 列是数值型，转换时忽略无法转换的值（设置为NaN）\n",
    "    choice_column = pd.to_numeric(medals_by_year[NOC], errors='coerce').reset_index(drop=True)\n",
    "\n",
    "    # 将 'NOC' 列与 done_programs_transposed 合并\n",
    "    df_combined = pd.concat([choice_column, done_programs_transposed], axis=1)\n",
    "\n",
    "    # 去除含有 NaN 的行\n",
    "    df_combined = df_combined.dropna()\n",
    "\n",
    "    # 计算皮尔逊相关系数矩阵\n",
    "    correlation_matrix = df_combined.corr(method='pearson')\n",
    "\n",
    "    # 将当前国家与所有列的相关性存入字典\n",
    "    correlation_dict[NOC] = correlation_matrix[NOC].drop(NOC)  # 排除自身的相关性\n",
    "\n",
    "# 将字典转换为 DataFrame 并转置\n",
    "correlation_df = pd.DataFrame(correlation_dict).transpose()\n",
    "\n",
    "# 去除含有 NaN 的行\n",
    "correlation_df = correlation_df.dropna()\n",
    "\n",
    "# for index, row in correlation_df.iterrows():\n",
    "#     # Get the indices of the top 3 largest values in the row\n",
    "#     to_indices = row.nlargest(3).index\n",
    "#     # Set all values in the row to 0\n",
    "#     correlation_df.loc[index] = 0\n",
    "#     # Set the top 3 largest values to 1\n",
    "#     correlation_df.loc[index, to_indices] = 1\n",
    "\n",
    "# 去除最后三列\n",
    "correlation_df = correlation_df.drop(correlation_df.columns[-3:], axis=1)\n",
    "\n",
    "correlation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储每行最大的三个值和列名\n",
    "max_values = []\n",
    "for row_index, row in correlation_df.iterrows():\n",
    "    # 获取当前行最大的三个元素及其列名\n",
    "    top_3 = row.nlargest(3)\n",
    "    # 创建一个字典包含列名和值\n",
    "    row_max_values = {'Row Name': row_index, 'Top 3 Columns': list(top_3.index), 'Top 3 Values': list(top_3.values)}\n",
    "    max_values.append(row_max_values)\n",
    "\n",
    "# 将这些数据转换为新的 DataFrame\n",
    "max_df = pd.DataFrame(max_values)\n",
    "\n",
    "# 打印新表\n",
    "max_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 最小二乘数据生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除含有NaN的行\n",
    "hosts_cleaned = hosts.dropna()\n",
    "\n",
    "# 删除第一列\n",
    "hosts_cleaned = hosts_cleaned.drop(hosts_cleaned.columns[1], axis=1)\n",
    "\n",
    "hosts_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    # Generate years from 1948 to 2020 with a step of 4\n",
    "    years = np.arange(1948, 2021, 4)\n",
    "    add_lst = hosts_cleaned.copy()\n",
    "    # Add random years to the 'Year' column in hosts_cleaned\n",
    "    add_lst['Year'] = np.random.choice(years, size=len(add_lst))\n",
    "    \n",
    "    # Fill the 'Year' column with random values from medals_by_year.columns\n",
    "    random_columns = np.random.choice(medals_by_year.columns, size=len(add_lst))\n",
    "    \n",
    "    # Output the modified DataFrame\n",
    "    add_lst['NOC'] = random_columns  # Replace Year with random column names\n",
    "    \n",
    "    # Vertically concatenate hosts_cleaned and add_lst\n",
    "    hosts_cleaned = pd.concat([hosts_cleaned, add_lst], ignore_index=True)\n",
    "\n",
    "# Output the modified DataFrame\n",
    "hosts_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_count_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 sport_count_year 是包含 'NOC', 'Year' 和 'Sport_Count' 列的 DataFrame\n",
    "\n",
    "# 合并 hosts_cleaned 和 medal_counts 表，按 'NOC' 和 'Year' 列进行连接\n",
    "merged_df = pd.merge(hosts_cleaned, medal_counts[['NOC', 'Year', 'Total']], on=['NOC', 'Year'], how='left')\n",
    "\n",
    "# 添加一列名为 'host'，值全为 1\n",
    "merged_df = merged_df.assign(host=1)\n",
    "\n",
    "# 进一步合并 sport_count_year 表，按 'NOC' 和 'Year' 列进行连接\n",
    "merged_df = pd.merge(merged_df, sport_count_year[['NOC', 'Year', 'Sport']], on=['NOC', 'Year'], how='left')\n",
    "\n",
    "final_df = pd.merge(merged_df, correlation_df, left_on='NOC', right_index=True, how='inner')\n",
    "\n",
    "final_df = final_df.dropna()\n",
    "\n",
    "# Set the first 27 rows of the 'host' column to 1, and the rest to 0\n",
    "final_df['host'] = 0  # Set all rows to 0\n",
    "final_df.loc[:26, 'host'] = 1  # Set the first 27 rows (index 0 to 26) to 1\n",
    "\n",
    "# Output the modified final_df\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# 假设 'final_df' 是已经合并好的 DataFrame，并且我们希望对 'Total' 进行回归\n",
    "\n",
    "# 选择所有列作为自变量\n",
    "X = final_df.drop(columns=['Total','Year','NOC'])  # 删除因变量 'Total' 列，所有其他列作为自变量\n",
    "\n",
    "# 因变量\n",
    "Y = final_df['Total']\n",
    "\n",
    "# 在自变量中添加常数项（截距项）\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# 构建并拟合回归模型\n",
    "model = sm.OLS(Y, X)  # OLS：普通最小二乘回归\n",
    "results = model.fit()\n",
    "\n",
    "# 输出回归结果的总结\n",
    "results.summary()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
